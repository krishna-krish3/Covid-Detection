{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9CZ35gVERDu5olNVqSLP/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna-krish3/Covid-Detection/blob/main/covid_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_XOhL8cNH-J"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb1gwgATNSIC",
        "outputId": "ff1cb6eb-ecc5-4cd4-cdee-5ea93871441d"
      },
      "source": [
        "#from cadence models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUXKFGxBNfwJ"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import helper\n",
        "import matplotlib.pyplot as plt\n",
        "transform = transforms.Compose([transforms.Resize(224),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.48, 0.45, 0.40], std=[0.23, 0.23, 0.23])])\n",
        "                                \n",
        "dataset = datasets.ImageFolder(\"/content/gdrive/MyDrive/Colab Notebooks/Covid_Images/\", transform = transform)\n",
        "bsize = len(dataset)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bsize, shuffle=False, pin_memory=True)\n",
        "images, labels = next(iter(dataloader))\n",
        "images, labels = images.cuda(), labels.cuda()\n",
        "#helper.imshow(images[0], normalize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6es1OdQNiGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133d9ff5-3b2c-4b79-fc6c-2f8f85e33e64"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7330"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZrvUv9QNn6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6f3777-e11d-45ff-9735-26e6723e3081"
      },
      "source": [
        "#cifar10...32x32\n",
        "num_classes=len(torch.unique(labels))\n",
        "num_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYu9dZ4GNr9C"
      },
      "source": [
        "trainlen=round(.8*len(dataset))\n",
        "vallen=round(0.1*len(dataset))\n",
        "testlen=len(dataset)-round(trainlen+vallen)\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [trainlen, vallen, testlen], generator=torch.Generator().manual_seed(42))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYFqCmnvNxZl"
      },
      "source": [
        "len(trainlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOiZweAuN00Q"
      },
      "source": [
        "len(testlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnBdFIitN3jd"
      },
      "source": [
        "len(vallen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPQGM2RaN6HO"
      },
      "source": [
        "from torch.utils.data import  DataLoader\n",
        "train_loader = DataLoader(train_set, batch_size=8, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=8, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=8, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrp2gj-UODkR"
      },
      "source": [
        "len(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NviiihhBOGyG"
      },
      "source": [
        "len(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlm1JcN3OJqQ"
      },
      "source": [
        "len(val_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpjjn3kRONFS"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models, utils\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(train_loader))\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46V-IYXiOUvt"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# #pretrained=True will download a pretrained network for us\n",
        "# model = models.densenet201(pretrained=True)\n",
        "# model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwCjuIDcOZur"
      },
      "source": [
        "###Rwightman Models\n",
        "# !pip install timm\n",
        "# import timm\n",
        "# import torch\n",
        "# from torch.autograd import Variable\n",
        "# model = timm.create_model('resnet18', pretrained=True)\n",
        "# model \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4585wfQmOdOB"
      },
      "source": [
        "#timm.list_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsS2J2X8Ogkq"
      },
      "source": [
        "!pip install pytorchcv torch>=0.4.0\n",
        "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "model = ptcv_get_model(\"regnetx002\", pretrained=True)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzDiKUkjOklK"
      },
      "source": [
        "#Freezing model parameters and defining the fully connected network to be attached to the model, loss function and the optimizer.\n",
        "#We there after put the model on the GPUs\n",
        "#num_ftrs = model.output.fc3.in_features\n",
        "#num_ftrs = model.output.fc.in_features\n",
        "num_ftrs = 368\n",
        "#num_ftrs = model.output.in_features\n",
        "for param in model.parameters():\n",
        "  param.require_grad = False\n",
        "fc = nn.Sequential(\n",
        "    # nn.Linear(1920, 1920),\n",
        "    # nn.ReLU(),\n",
        "    # nn.Dropout(0.4),\n",
        "    \n",
        "    nn.Linear(num_ftrs,num_classes),\n",
        "    #nn.Dropout(0.6),\n",
        "    #nn.LogSoftmax(dim=1)\n",
        "    \n",
        ")\n",
        "model.output = fc\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#Over here we want to only update the parameters of the classifier so\n",
        "optimizer = torch.optim.SGD(model.output.parameters(), lr=0.003)\n",
        "#optimizer = torch.optim.Adam(model.output.parameters(), lr = 0.003)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9qyUX8bOqt4"
      },
      "source": [
        "num_epochs = 15\n",
        "valid_loader = val_loader\n",
        "# keeping-track-of-losses \n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # keep-track-of-training-and-validation-loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    correct = 0\n",
        "    total=0\n",
        "    # training-the-model\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        # move-tensors-to-GPU \n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        # clear-the-gradients-of-all-optimized-variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
        "        output = model(data)\n",
        "        # calculate-the-batch-loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n",
        "        loss.backward()\n",
        "        # perform-a-ingle-optimization-step (parameter-update)\n",
        "        optimizer.step()\n",
        "        # update-training-loss\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "        ##TODAY\n",
        "        _,pred = torch.max(output, dim=1)\n",
        "        correct += torch.sum(pred==target).item()\n",
        "        total += target.size(0)\n",
        "    train_acc.append(100 * correct / total)\n",
        "    # validate-the-model\n",
        "    model.eval()\n",
        "    total_t=0\n",
        "    correct_t=0\n",
        "    for data, target in valid_loader:\n",
        "        \n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        output = model(data)\n",
        "        \n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        # update-average-validation-loss \n",
        "        valid_loss += loss.item() * data.size(0)\n",
        "        ###today\n",
        "        _,pred_t = torch.max(output, dim=1)\n",
        "        correct_t += torch.sum(pred_t==target).item()\n",
        "        total_t += target.size(0)\n",
        "    val_acc.append(100 * correct_t / total_t)\n",
        "    # calculate-average-losses\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "        \n",
        "    # print-training/validation-statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyWoRwTDOxEP"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-A_oJjgO07K"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ4_JyN2O4UH"
      },
      "source": [
        "# test-the-model\n",
        "model.eval()  # it-disables-dropout\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "          \n",
        "    print('Test Accuracy of the model: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save \n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hSwAAxVO945"
      },
      "source": [
        "# def train_model(train_dl, model):\n",
        "#     # define the optimization\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "# #Over here we want to only update the parameters of the classifier so\n",
        "#     optimizer = torch.optim.SGD(model.output.parameters(), lr=0.003)\n",
        "#     # enumerate epochs\n",
        "#     losses = []\n",
        "#     running_corrects = 0\n",
        "#     epochacc = []\n",
        "#     for epoch in range(10):\n",
        "#         # enumerate mini batches\n",
        "#         running_loss = 0.0\n",
        "#         for i, (inputs, targets) in enumerate(train_dl):\n",
        "#             inputs, targets = inputs.to(device), targets.to(device)\n",
        "#             # clear the gradients\n",
        "#             optimizer.zero_grad()\n",
        "#             # compute the model output\n",
        "#             yhat = model(inputs)\n",
        "#             # calculate loss\n",
        "#             loss = criterion(yhat, targets)\n",
        "#             _, preds = torch.max(yhat, 1)\n",
        "#             # credit assignment\n",
        "#             loss.backward()\n",
        "#             # update model weights\n",
        "#             optimizer.step()\n",
        "#             running_loss += loss.item() * inputs.size(0)\n",
        "#             running_corrects += torch.sum(preds == targets.data)\n",
        "#         epoch_loss = running_loss / len(train_loader)\n",
        "#         epoch_acc = running_corrects.double() / len(train_loader)\n",
        "#         losses.append(epoch_loss)\n",
        "#         epoch_acc.tolist()\n",
        "#         epochacc.append(epoch_acc)\n",
        "#         running_corrects.append(epoch_acc)\n",
        "#         print(epoch_acc) \n",
        "#     return losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2_lJPqnPEl3"
      },
      "source": [
        "# from numpy import argmax\n",
        "# from numpy import vstack\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# def evaluate_model(test_dl, model):\n",
        "#     predictions, actuals = list(), list()\n",
        "#     for i, (inputs, targets) in enumerate(test_dl):\n",
        "#         inputs, targets = inputs.to(device), targets.to(device)\n",
        "#         # evaluate the model on the test set\n",
        "#         yhat = model(inputs)\n",
        "#         # retrieve numpy array\n",
        "#         yhat = yhat.cpu().detach().numpy()\n",
        "#         actual = targets.cpu().numpy()\n",
        "#         # convert to class labels\n",
        "#         yhat = argmax(yhat, axis=1)\n",
        "#         # reshape for stacking\n",
        "#         actual = actual.reshape((len(actual), 1))\n",
        "#         yhat = yhat.reshape((len(yhat), 1))\n",
        "#         # store\n",
        "#         predictions.append(yhat)\n",
        "#         actuals.append(actual)\n",
        "#     predictions, actuals = vstack(predictions), vstack(actuals)\n",
        "#     # calculate accuracy\n",
        "#     acc = accuracy_score(actuals, predictions)\n",
        "#     return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT6P8FGjPIo_"
      },
      "source": [
        "#losses = train_model(train_loader, model)\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1tL_YrKPOme"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(losses, label='TrainLoss', marker='o')\n",
        "# #plt.plot(epochacc, label='TrainAcc', marker='x')\n",
        "#   # plt.plot(x, history['val_loss'], label='val', marker='o')\n",
        "#     # plt.plot(x, history['train_loss'], label='train', marker='o')\n",
        "# plt.title('Loss per epoch'); plt.ylabel('Loss');\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend(), plt.grid()\n",
        "# plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PotO_3ynPW4K"
      },
      "source": [
        "# trainacc = evaluate_model(train_loader, model)\n",
        "# print('TrainAccuracy: %.3f' % trainacc)\n",
        "# valacc = evaluate_model(val_loader, model)\n",
        "# print('ValAccuracy: %.3f' % valacc)\n",
        "# testacc = evaluate_model(test_loader, model)\n",
        "# print('Accuracy: %.3f' % testacc)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}